{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6f2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "import pandas as pd\n",
    "import os\n",
    "import gradio as gr\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b246ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "\n",
    "model_name = \"openai/gpt-oss-20b\"\n",
    "temperature = 0.01\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=model_name,\n",
    "    temperature=temperature,\n",
    "    max_tokens=None,\n",
    "    groq_api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87e6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import RateLimitError\n",
    "\n",
    "def enforce_rate_limit(messages):\n",
    "    while True:\n",
    "        try:\n",
    "            return (\n",
    "                llm.invoke(messages)\n",
    "            )\n",
    "        except RateLimitError as e:\n",
    "            print(\"Rate limit reached. Waiting 60 seconds...\")\n",
    "            time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19f07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_summary_generation_prompt(topic: str, summary_text):\n",
    "    return f\"\"\"\n",
    "    You are a highly skilled code quality analysis assistant.\n",
    "\n",
    "    Your task is to generate a clear, concise, and insightful **overall summary** for a software repository, focused specifically on the topic: **{topic}**.\n",
    "\n",
    "    You are provided with a collection of **raw code review issues** which are extracted from individual files or modules related to this topic:\n",
    "    ------------------------\n",
    "    {summary_text}\n",
    "    ------------------------\n",
    "\n",
    "    Please analyze the issues and synthesize the key patterns, recurring violations, and critical observations related to **{topic}**. Your summary should:\n",
    "\n",
    "    1. Highlight only the most significant or frequent types of issues found in the input.\n",
    "    2. Identify common trends, such as repeated bad practices or patterns of neglect.\n",
    "    3. Emphasize any critical or high-severity issues that require urgent remediation. Be specific where possible.\n",
    "    4. Highlight major concerns only. Do not comment on what needs to be changed.\n",
    "    4. Maintain a professional, concise, and objective tone.\n",
    "\n",
    "    Return only the final textual summary. Do not repeat or restate the raw input. Do not format your response as a list or dictionary — only provide a well-written paragraph.\n",
    "    \"\"\"\n",
    "\n",
    "def generate_overall_issue_summary(topic: str, summary_text: list[str]) -> dict:\n",
    "    \n",
    "    # Combine and build prompt\n",
    "    combined_prompt = issue_summary_generation_prompt(topic, summary_text)\n",
    "\n",
    "    # Invoke LLM\n",
    "    # response = llm.invoke([HumanMessage(content=combined_prompt)])\n",
    "    messages = [HumanMessage(content=combined_prompt)]\n",
    "    response = enforce_rate_limit(messages)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_summary_generation_prompt(topic: str, summary_text):\n",
    "    return f\"\"\"\n",
    "    You are a highly skilled code quality analysis assistant.\n",
    "\n",
    "    Your task is to generate a clear, concise, and insightful **refactoring summary** for a software repository, focused specifically on the topic: **{topic}**.\n",
    "\n",
    "    You are provided with a list of summaries describing the **code changes that were done** in individual files or modules related to the topic: {topic}\n",
    "    ------------------------\n",
    "    {summary_text}\n",
    "    ------------------------\n",
    "\n",
    "    Please analyze the described changes and synthesize the key improvements, recurring refactor patterns, and overall impact of the modifications related to **{topic}**. Your summary should:\n",
    "\n",
    "    1. Highlight the most important or impactful changes made across the codebase.\n",
    "    2. Identify common refactoring patterns or trends (e.g., modularization, removal of duplication, performance improvements).\n",
    "    3. Mention any changes that address critical or high-severity issues, if applicable.\n",
    "    4. The 'summary_text' contains all the **changes made**.\n",
    "    5. Do not mention what can be refactored, but only on what changes are actually made.\n",
    "    6. Maintain a professional, concise, and objective tone.\n",
    "\n",
    "    Return only the final textual summary. Do not repeat or restate the raw input. Do not format your response as a list or dictionary — only provide a well-written paragraph.\n",
    "    \"\"\"\n",
    "\n",
    "def generate_overall_refactor_summary(topic: str, summary_text: list[str]) -> dict:\n",
    "    \n",
    "    # Combine and build prompt\n",
    "    combined_prompt = refactor_summary_generation_prompt(topic, summary_text)\n",
    "\n",
    "    # Invoke LLM\n",
    "    # response = llm.invoke([HumanMessage(content=combined_prompt)])\n",
    "    messages = [HumanMessage(content=combined_prompt)]\n",
    "    response = enforce_rate_limit(messages)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37af419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_issue_summary_generation_prompt(text_code_styling, text_dry_modularity, text_security):\n",
    "    return f\"\"\"You are a code quality analysis assistant.\n",
    "\n",
    "You are given three issue summaries highlighting problems identified in a codebase, each focusing on a different aspect:\n",
    "1. Code Styling – formatting inconsistencies, naming violations, and readability issues.\n",
    "2. DRY and Modularity – code duplication, poor abstraction, and lack of reuse.\n",
    "3. Security Compliance – unsafe practices, vulnerabilities, and deviations from security best practices.\n",
    "\n",
    "Each summary is provided below. Your task is to:\n",
    "- Carefully review the three issue summaries.\n",
    "- Synthesize and interpret the most important insights across all three areas.\n",
    "- Identify critical patterns, recurring violations, or any systemic problems affecting code quality.\n",
    "- Write a **concise, high-level summary** that reflects the overall quality and areas needing improvement.\n",
    "- Do **not** copy or restate the full summaries; focus on generating a holistic assessment of the issues only, do not suggest any changes.\n",
    "\n",
    "Return only the summary text. Do not include any formatting, lists, or metadata — just plain text.\n",
    "\n",
    "---\n",
    "\n",
    "**Code Styling Issues Summary:**\n",
    "{text_code_styling}\n",
    "\n",
    "**DRY & Modularity Issues Summary:**\n",
    "{text_dry_modularity}\n",
    "\n",
    "**Security Compliance Issues Summary:**\n",
    "{text_security}\n",
    "\"\"\"\n",
    "\n",
    "def generate_overall_repo_issue_summary(text1, text2, text3):\n",
    "    \n",
    "    # Combine and build prompt\n",
    "    combined_prompt = overall_issue_summary_generation_prompt(text1, text2, text3)\n",
    "\n",
    "    # Invoke LLM\n",
    "    # response = llm.invoke([HumanMessage(content=combined_prompt)])\n",
    "    messages = [HumanMessage(content=combined_prompt)]\n",
    "    response = enforce_rate_limit(messages)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ed3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_refactor_summary_generation_prompt(text_code_styling, text_dry_modularity, text_security):\n",
    "    return f\"\"\"You are a code quality analysis assistant.\n",
    "\n",
    "You are given summaries describing refactoring changes made to a code repository, grouped into three key areas:\n",
    "1. Code Styling – improvements related to formatting, naming conventions, readability, and consistency.\n",
    "2. DRY and Modularity – changes addressing code duplication, abstraction, reuse, and structural modularity.\n",
    "3. Security Compliance – enhancements targeting security risks, vulnerabilities, and adherence to best practices.\n",
    "\n",
    "Each summary below describes the changes that have already been made. Your task is to:\n",
    "- Read and analyze the three refactoring summaries carefully.\n",
    "- Synthesize and interpret the overall improvements to the codebase.\n",
    "- Identify recurring patterns or themes across the changes.\n",
    "- Write a **concise, high-level summary** of how the refactoring has improved the codebase.\n",
    "- Emphasize the overall impact on maintainability, readability, structure, and security.\n",
    "\n",
    "Return only the final summary text — do not include lists, formatting, or restate the input directly.\n",
    "\n",
    "---\n",
    "\n",
    "**Code Styling Refactoring Summary:**\n",
    "{text_code_styling}\n",
    "\n",
    "**DRY & Modularity Refactoring Summary:**\n",
    "{text_dry_modularity}\n",
    "\n",
    "**Security Compliance Refactoring Summary:**\n",
    "{text_security}\n",
    "\"\"\"\n",
    "\n",
    "def generate_overall_repo_refactor_summary(text1, text2, text3):\n",
    "    \n",
    "    # Combine and build prompt\n",
    "    combined_prompt = overall_refactor_summary_generation_prompt(text1, text2, text3)\n",
    "\n",
    "    # Invoke LLM\n",
    "    # response = llm.invoke([HumanMessage(content=combined_prompt)])\n",
    "    messages = [HumanMessage(content=combined_prompt)]\n",
    "    response = enforce_rate_limit(messages)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5168841",
   "metadata": {},
   "source": [
    "# Final Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92412570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Agents\n",
    "from ReviewAgents.CodeStyle import create_code_quality_graph\n",
    "from ReviewAgents.DRY import run_dry_modularity_compliance_agent\n",
    "from ReviewAgents.Security import run_security_compliance_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef328f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# graph = create_code_quality_graph()\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6a697d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_code_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f094fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# File Level Review Lists\n",
    "codeStyle_file_level_review_list = []\n",
    "dry_file_level_review_list = []\n",
    "security_file_level_review_list = []\n",
    "    \n",
    "# Line Level Review Lists\n",
    "codeStyle_line_level_review_list = []\n",
    "dry_line_level_review_list = []\n",
    "security_line_level_review_list = []\n",
    "\n",
    "# folder_path = 'Test_Repository'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4ead3",
   "metadata": {},
   "source": [
    "# Creating Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17acadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_repo_level_df():\n",
    "    \n",
    "    # Code Style and Consistency\n",
    "    codeStyle_file_level_issue_summary_list = []\n",
    "    codeStyle_file_level_refactor_summary_list = []\n",
    "    codeStyle_violations = 0\n",
    "    codeStyle_score = 0\n",
    "    codeStyle_score_avg = 0\n",
    "    for single_dict in codeStyle_file_level_review_list:\n",
    "        codeStyle_file_level_issue_summary_list.append(single_dict[\"issue_summary\"])\n",
    "        codeStyle_file_level_refactor_summary_list.append(single_dict[\"refactor_summary\"])\n",
    "        codeStyle_violations += single_dict[\"violations\"]\n",
    "        codeStyle_score += single_dict[\"score\"]\n",
    "\n",
    "    if codeStyle_file_level_review_list:\n",
    "        codeStyle_score_avg = codeStyle_score / len(codeStyle_file_level_review_list)\n",
    "    else:\n",
    "        codeStyle_score_avg = 0\n",
    "\n",
    "    codeStyle_repo_level_issue_summary = generate_overall_issue_summary(\"Code Style and Consistency\", codeStyle_file_level_issue_summary_list)\n",
    "    codeStyle_repo_level_refactor_summary = generate_overall_refactor_summary(\"Code Style and Consistency\", codeStyle_file_level_refactor_summary_list)\n",
    "    \n",
    "    # DRY and Modularity\n",
    "    dry_file_level_issue_summary_list = []\n",
    "    dry_file_level_refactor_summary_list = []\n",
    "    dry_violations = 0\n",
    "    dry_score = 0\n",
    "    dry_score_avg = 0\n",
    "    for single_dict in dry_file_level_review_list:\n",
    "        dry_file_level_issue_summary_list.append(single_dict[\"issue_summary\"])\n",
    "        dry_file_level_refactor_summary_list.append(single_dict[\"refactor_summary\"])\n",
    "        dry_violations += single_dict[\"violations\"]\n",
    "        dry_score += single_dict[\"score\"]\n",
    "\n",
    "    if dry_file_level_review_list:\n",
    "        dry_score_avg = dry_score / len(dry_file_level_review_list)\n",
    "    else:\n",
    "        dry_score_avg = 0\n",
    "\n",
    "    dry_repo_level_issue_summary = generate_overall_issue_summary(\"DRY and Modularity\", dry_file_level_issue_summary_list)\n",
    "    dry_repo_level_refactor_summary = generate_overall_refactor_summary(\"DRY and Modularity\", dry_file_level_refactor_summary_list)\n",
    "    \n",
    "    \n",
    "    # Security Compliances\n",
    "    security_file_level_issue_summary_list = []\n",
    "    security_file_level_refactor_summary_list = []\n",
    "    security_violations = 0\n",
    "    security_score = 0\n",
    "    security_score_avg = 0\n",
    "    for single_dict in security_file_level_review_list:\n",
    "        security_file_level_issue_summary_list.append(single_dict[\"issue_summary\"])\n",
    "        security_file_level_refactor_summary_list.append(single_dict[\"refactor_summary\"])\n",
    "        security_violations += single_dict[\"violations\"]\n",
    "        security_score += single_dict[\"score\"]\n",
    "\n",
    "    if security_file_level_review_list:\n",
    "        security_score_avg = security_score / len(security_file_level_review_list)\n",
    "    else:\n",
    "        security_score_avg = 0\n",
    "\n",
    "    security_repo_level_issue_summary = generate_overall_issue_summary(\"Security Compliances\", security_file_level_issue_summary_list)\n",
    "    security_repo_level_refactor_summary = generate_overall_refactor_summary(\"Security Compliances\", security_file_level_refactor_summary_list)\n",
    "    \n",
    "    # Overall Results\n",
    "    overall_violations = codeStyle_violations + dry_violations + security_violations\n",
    "    overall_score_avg = (security_score_avg + dry_score_avg + codeStyle_score_avg) / 3\n",
    "    overall_repo_level_issue_summary = generate_overall_repo_issue_summary(codeStyle_repo_level_issue_summary, dry_repo_level_issue_summary, security_repo_level_issue_summary)\n",
    "    overall_repo_level_refactor_summary = generate_overall_repo_refactor_summary(codeStyle_repo_level_refactor_summary, dry_repo_level_refactor_summary, security_repo_level_refactor_summary)\n",
    "    \n",
    "    # Create Repo Level DataFrame\n",
    "    repo_level_data = [\n",
    "        {\"Review Category\": \"Code Style and Consistency\", \"Vulnerabilities Flagged\": codeStyle_violations, \"AI Review Score\": codeStyle_score_avg, \"AI Reviewer Comments\": codeStyle_repo_level_issue_summary, \"AI Suggested Fixes\": codeStyle_repo_level_refactor_summary},\n",
    "        {\"Review Category\": \"DRY and Modularity\", \"Vulnerabilities Flagged\": dry_violations, \"AI Review Score\": dry_score_avg, \"AI Reviewer Comments\": dry_repo_level_issue_summary, \"AI Suggested Fixes\": dry_repo_level_refactor_summary},\n",
    "        {\"Review Category\": \"Security Compliences\", \"Vulnerabilities Flagged\": security_violations, \"AI Review Score\": security_score_avg, \"AI Reviewer Comments\": security_repo_level_issue_summary, \"AI Suggested Fixes\": security_repo_level_refactor_summary},\n",
    "        {\"Review Category\": \"Overall\", \"Vulnerabilities Flagged\": overall_violations, \"AI Review Score\": overall_score_avg, \"AI Reviewer Comments\": overall_repo_level_issue_summary, \"AI Suggested Fixes\": overall_repo_level_refactor_summary}\n",
    "    ]\n",
    "\n",
    "    final_repo_review_df = pd.DataFrame(repo_level_data)\n",
    "    return final_repo_review_df    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37424531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_level_df():\n",
    "    \n",
    "    codeStyle_file_level_df = pd.DataFrame(codeStyle_file_level_review_list)\n",
    "    dry_file_level_df = pd.DataFrame(dry_file_level_review_list)\n",
    "    security_file_level_df = pd.DataFrame(security_file_level_review_list)\n",
    "\n",
    "    # Merge the Dataframes\n",
    "    file_level_merged = pd.concat([codeStyle_file_level_df, dry_file_level_df, security_file_level_df], ignore_index=True)\n",
    "    return file_level_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ddb9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_level_df():\n",
    "    codeStyle_line_level_df = pd.DataFrame(codeStyle_line_level_review_list)\n",
    "    dry_line_level_df = pd.DataFrame(dry_line_level_review_list)\n",
    "    security_line_level_df = pd.DataFrame(security_line_level_review_list)\n",
    "\n",
    "    # Changing Column Names\n",
    "    codeStyle_line_level_df = codeStyle_line_level_df.rename(columns={\n",
    "        'refactored_python_script': 'refactored_script',\n",
    "        'original_python_script': 'original_code_script'\n",
    "    })\n",
    "    \n",
    "    dry_line_level_df = dry_line_level_df.rename(columns={\n",
    "        'original_sql_script': 'original_code_script'\n",
    "    })\n",
    "\n",
    "    # Merge the Dataframes\n",
    "    line_level_merged = pd.concat([codeStyle_line_level_df, dry_line_level_df, security_line_level_df], ignore_index=True)\n",
    "    return line_level_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9866d",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31b2b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_DIR = \"uploaded_folder_gradio\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "def clear_uploaded_files():\n",
    "    \"\"\"Clears the contents of the UPLOAD_DIR.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(UPLOAD_DIR):\n",
    "            for filename in os.listdir(UPLOAD_DIR):\n",
    "                file_path = os.path.join(UPLOAD_DIR, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing files: {e}\")\n",
    "        raise gr.Error(f\"Error clearing files: {e}\")\n",
    "        \n",
    "def create_repo_summary_table():\n",
    "    df = create_repo_level_df()\n",
    "    # df = pd.read_excel('code_review_report_test.xlsx', sheet_name='Repository Review')\n",
    "    return df if not df.empty else pd.DataFrame([{\"No data\": \"Repository summary is empty\"}])\n",
    "\n",
    "\n",
    "def process_uploaded_files(files):\n",
    "    if not files:\n",
    "        yield 0, \"Please upload files first.\", gr.update(visible=False), gr.update(visible=False), None\n",
    "        return\n",
    "\n",
    "    total_files = len(files)\n",
    "    processed = 0\n",
    "    \n",
    "    # Calculate total steps: 3 agents per file\n",
    "    total_steps = total_files * 3 \n",
    "    current_step = 0\n",
    "\n",
    "    yield 0, f\"Processing {total_files} files...\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "    # Save uploaded files\n",
    "    for temp_file in files:\n",
    "        original_filename = os.path.basename(temp_file.name)\n",
    "        if hasattr(temp_file, 'orig_name') and temp_file.orig_name:\n",
    "            original_filename = temp_file.orig_name\n",
    "\n",
    "        file_path = os.path.join(UPLOAD_DIR, original_filename)\n",
    "        shutil.copy(temp_file.name, file_path)\n",
    "\n",
    "    # Process each file\n",
    "    for filename in os.listdir(UPLOAD_DIR):\n",
    "        file_path = os.path.join(UPLOAD_DIR, filename)\n",
    "\n",
    "        if not os.path.isfile(file_path) or not (file_path.endswith(\".py\") or file_path.endswith(\".sql\")):\n",
    "            continue\n",
    "\n",
    "        # File processing step\n",
    "        # current_step += 1\n",
    "        progress = int((current_step / total_steps) * 100)\n",
    "        yield progress, f\"🔍 Processing file: {filename}\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "        try:\n",
    "            # Code Style Agent\n",
    "            yield progress, f\"🧹 Running Code Style & Consistency Agent for file {filename}\", gr.update(visible=False), gr.update(visible=False), None\n",
    "            graph = create_code_quality_graph()\n",
    "            codeStyle_response = graph.invoke({\"filename\": file_path})[\"evaluationReport\"]\n",
    "            print(\"###code style response###\", codeStyle_response)\n",
    "            \n",
    "            # Update progress \n",
    "            current_step += 1\n",
    "            progress = int((current_step / total_steps) * 100)\n",
    "            yield progress, f\"✅ Code Style Agent completed for {filename}.\", gr.update(visible=False), gr.update(visible=False), None\n",
    "            \n",
    "            # DRY Agent\n",
    "            yield progress, f\"🔁 Running DRY & Modularity Agent for file {filename}\", gr.update(visible=False), gr.update(visible=False), None\n",
    "            \n",
    "            dry_response = run_dry_modularity_compliance_agent(file_path)\n",
    "            print(\"##dry response##\", dry_response)\n",
    "            \n",
    "            # Update progress \n",
    "            current_step += 1\n",
    "            progress = int((current_step / total_steps) * 100)\n",
    "            yield progress, f\"✅ DRY & Modularity Agent completed for {filename}.\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "            # Security Agent\n",
    "            yield progress, f\"🔐 Running Security Compliance Agent for file {filename}\", gr.update(visible=False), gr.update(visible=False), None\n",
    "            security_response = run_security_compliance_agent(file_path)\n",
    "            print(\"##security response##\", security_response)\n",
    "            \n",
    "            # Update progress \n",
    "            current_step += 1\n",
    "            progress = int((current_step / total_steps) * 100)\n",
    "            yield progress, f\"✅ Security Compliance Agent completed for {filename}.\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "            # File level data\n",
    "            codeStyle_file_level_review_list.append({\n",
    "                \"filename\": filename,\n",
    "                \"category\": \"Code Style & Consistency\",\n",
    "                \"score\": codeStyle_response[\"evaluation_score\"],\n",
    "                \"issue_summary\": codeStyle_response[\"evaluation_issue_summary\"],\n",
    "                \"refactor_summary\": codeStyle_response[\"evaluation_refactor_summary\"],\n",
    "                \"violations\": codeStyle_response[\"violations_count\"]\n",
    "            })\n",
    "\n",
    "            dry_file_level_review_list.append({\n",
    "                \"filename\": filename,\n",
    "                \"category\": \"DRY & Modularity\",\n",
    "                \"score\": dry_response[\"evaluation_score\"],\n",
    "                \"issue_summary\": dry_response[\"evaluation_issue_summary\"],\n",
    "                \"refactor_summary\": dry_response[\"evaluation_refactor_summary\"],\n",
    "                \"violations\": len(dry_response[\"evaluation_details\"])\n",
    "            })\n",
    "\n",
    "            security_file_level_review_list.append({\n",
    "                \"filename\": filename,\n",
    "                \"category\": \"Security Compliance\",\n",
    "                \"score\": security_response[\"evaluation_score\"],\n",
    "                \"issue_summary\": security_response[\"evaluation_issue_summary\"],\n",
    "                \"refactor_summary\": security_response[\"evaluation_refactor_summary\"],\n",
    "                \"violations\": len(security_response[\"evaluation_details\"])\n",
    "            })\n",
    "\n",
    "            # Line Level Reviews\n",
    "            x = codeStyle_response[\"evaluation_details\"]\n",
    "            y = dry_response[\"evaluation_details\"]\n",
    "            z = security_response[\"evaluation_details\"]\n",
    "\n",
    "            for i in x:\n",
    "                i[\"filename\"] = filename\n",
    "                i[\"category\"] = \"Code Style & Consistency\"\n",
    "                codeStyle_line_level_review_list.append(i)\n",
    "\n",
    "            for i in y:\n",
    "                i[\"filename\"] = filename\n",
    "                i[\"category\"] = \"DRY and Modularity\"\n",
    "                dry_line_level_review_list.append(i)\n",
    "\n",
    "            for i in z:\n",
    "                i[\"filename\"] = filename\n",
    "                i[\"category\"] = \"Security Compliance\"\n",
    "                security_line_level_review_list.append(i)\n",
    "\n",
    "        except Exception as agent_err:\n",
    "            # Still increment step counter even on error to maintain progress accuracy\n",
    "            current_step += 3  # Skip the remaining 3 steps for this file\n",
    "            progress = int((current_step / total_steps) * 100)\n",
    "            yield progress, f\"❌ Error processing {filename}: {agent_err}\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "        processed += 1\n",
    "        yield progress, f\"🏁 Finished Reviewing {filename} ({processed}/{total_files})\", gr.update(visible=False), gr.update(visible=False), None\n",
    "\n",
    "    clear_uploaded_files()\n",
    "    repo_df = create_repo_summary_table()\n",
    "    yield 100, \"✅ All files processed. See summary below.\", gr.update(visible=True), gr.update(value=repo_df, visible=True), None\n",
    "    # yield 100, \"✅ All files processed. You can now generate the report.\", gr.update(visible=True), None\n",
    "\n",
    "\n",
    "def generate_excel_report():\n",
    "    \"\"\"\n",
    "    Generates the multi-sheet Excel report and returns its path for download.\n",
    "    Enhanced with step-by-step progress tracking.\n",
    "    \"\"\"\n",
    "    total_steps = 3  # Create repo df, file df, line df, write Excel\n",
    "    current_step = 0\n",
    "    \n",
    "    # Step 1: Create repository level dataframe\n",
    "    # current_step += 1\n",
    "    progress = int((current_step / total_steps) * 100)\n",
    "    yield progress, \"📊 Creating repository level analysis...\", None\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create repository level dataframe\n",
    "        yield progress, \"📊 Creating repository level analysis...\", None\n",
    "        final_repo_review_df = create_repo_level_df()\n",
    "        \n",
    "        # Update progress AFTER repo analysis is complete\n",
    "        current_step += 1\n",
    "        progress = int((current_step / total_steps) * 100)\n",
    "        yield progress, \"✅ Repository level analysis completed.\", None\n",
    "        \n",
    "        # Step 2: Create file level dataframe  \n",
    "        yield progress, \"📁 Creating file level analysis...\", None\n",
    "        file_level_merged_df = create_file_level_df()\n",
    "        \n",
    "        # Update progress AFTER file analysis is complete\n",
    "        current_step += 1\n",
    "        progress = int((current_step / total_steps) * 100)\n",
    "        yield progress, \"✅ File level analysis completed.\", None\n",
    "        \n",
    "        # Step 3: Create line level dataframe\n",
    "        yield progress, \"📝 Creating line level analysis...\", None\n",
    "        line_level_merged_df = create_line_level_df()\n",
    "        \n",
    "        # Update progress AFTER line analysis is complete\n",
    "        current_step += 1\n",
    "        progress = int((current_step / total_steps) * 100)\n",
    "        yield progress, \"✅ Line level analysis completed.\", None\n",
    "        \n",
    "        # Step 4: Generate Excel file\n",
    "        yield progress, \"💾 Generating Excel file...\", None\n",
    "        \n",
    "        output_dir = \"ai_code_review_reports\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        filename = f\"code_review_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "            final_repo_review_df.to_excel(writer, sheet_name='Repository Review', index=False)\n",
    "            file_level_merged_df.to_excel(writer, sheet_name='Files Review', index=False)\n",
    "            line_level_merged_df.to_excel(writer, sheet_name='Line Level Review', index=False)\n",
    "\n",
    "        # Update progress AFTER Excel file is generated\n",
    "        current_step += 1\n",
    "        progress = int((current_step / total_steps) * 100)\n",
    "        status_message = f\"✅ Excel report generated successfully! Click below to download.\"\n",
    "        yield 100, status_message, gr.update(value=output_file, visible=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"❌ Error generating Excel: {e}\"\n",
    "        print(error_message)\n",
    "        raise gr.Error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb1b0386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://3862d939ba2ce72d11.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3862d939ba2ce72d11.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Gradio UI ---\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🧠 AI Code Review Report Generator\")\n",
    "    gr.Markdown(\"Upload `.py` or `.sql` files. Run code quality agents, then export the report.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            upload_button = gr.File(label=\"Upload Code Files\", file_count=\"multiple\", file_types=['.py', '.sql'])\n",
    "        with gr.Column(scale=2):\n",
    "            progress_bar = gr.Slider(minimum=0, maximum=100, value=0, interactive=False, label=\"Progress\")\n",
    "            status_text = gr.Text(label=\"Status Message\", value=\"Ready to upload files...\")\n",
    "\n",
    "    # Full-width repo summary table\n",
    "    repo_summary_table = gr.Dataframe(\n",
    "        label=\"📘 Repository Summary\",\n",
    "        visible=False,\n",
    "        interactive=False,\n",
    "        wrap=True\n",
    "    )\n",
    "\n",
    "    export_button = gr.Button(\"Generate Detailed Review\", variant=\"primary\", visible=False)\n",
    "    download_link = gr.File(label=\"Download Report\", visible=False)\n",
    "\n",
    "    upload_button.upload(\n",
    "        fn=process_uploaded_files,\n",
    "        inputs=upload_button,\n",
    "        outputs=[progress_bar, status_text, export_button, repo_summary_table, download_link]\n",
    "    )\n",
    "\n",
    "    export_button.click(\n",
    "        fn=generate_excel_report,\n",
    "        inputs=None,\n",
    "        outputs=[progress_bar, status_text, download_link]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Code Style And Consistency Review on the file : uploaded_folder_gradio\\decorators.py ---\n",
      "\n",
      "--- Language Identification Response ---\n",
      "```json\n",
      "{\n",
      "  \"result\": {\n",
      "    \"major_language\": \"Python\",\n",
      "    \"minor_languages\": []\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "{\n",
      "  \"result\": {\n",
      "    \"major_language\": \"Python\",\n",
      "    \"minor_languages\": []\n",
      "  }\n",
      "}\n",
      "Language detected: {'major_language': 'Python', 'minor_languages': []}\n",
      "\n",
      "########################################################\n",
      "\n",
      "Detected major language as Python, routing to Python analysis node.\n",
      "\n",
      "This is Python code, routing to Python analysis node.\n",
      "\n",
      "Pylint imported successfully.\n",
      "Inline comments analysis complete: {'report': [{'score': 8.0, 'severity': 'Minor', 'start_line': 8, 'end_line': 8, 'issue': \"The comment is missing to explain the purpose of the 'user_id' check in the session.\"}, {'score': 8.0, 'severity': 'Minor', 'start_line': 9, 'end_line': 9, 'issue': 'The comment is missing to explain the logging of unauthorized access attempts.'}], 'violations_count': 2, 'base_score': 8.0}\n",
      "\n",
      "########################################################\n",
      "\n",
      "Pylint analysis complete: {'report': [{'score': 0.0, 'severity': 'Moderate', 'start_line': 1, 'end_line': 1, 'issue': 'C0114: Missing module docstring (missing-module-docstring)'}, {'score': 0.0, 'severity': 'Moderate', 'start_line': 4, 'end_line': 4, 'issue': 'C0116: Missing function or method docstring (missing-function-docstring)'}], 'violations_count': 2, 'base_score': 7.0}\n",
      "\n",
      "########################################################\n",
      "\n",
      "Merged reports: {'report': [{'score': 0.0, 'severity': 'Moderate', 'start_line': 1, 'end_line': 1, 'issue': 'C0114: Missing module docstring (missing-module-docstring)'}, {'score': 0.0, 'severity': 'Moderate', 'start_line': 4, 'end_line': 4, 'issue': 'C0116: Missing function or method docstring (missing-function-docstring)'}, {'score': 8.0, 'severity': 'Minor', 'start_line': 8, 'end_line': 8, 'issue': \"The comment is missing to explain the purpose of the 'user_id' check in the session.\"}, {'score': 8.0, 'severity': 'Minor', 'start_line': 9, 'end_line': 9, 'issue': 'The comment is missing to explain the logging of unauthorized access attempts.'}], 'violations_count': 4, 'base_score': 7.5}\n",
      "\n",
      "########################################################\n",
      "\n",
      "Code Style: {'violations_count': 4, 'evaluation_score': 4.0, 'evaluation_issue_summary': 'The code has 4 issues, including missing module and function docstrings, and missing comments to explain the purpose of certain checks and logging. The issues are mostly minor or moderate, with scores ranging from 0.0 to 8.0.', 'evaluation_refactor_summary': \"The refactored code includes added docstrings for the module and the login_required function, as well as comments to explain the purpose of the 'user_id' check and the logging of unauthorized access attempts. These changes improve the code's readability and maintainability.\", 'evaluation_details': [{'start_line_number': 1, 'end_line_number': 1, 'original_python_script': 'from functools import wraps', 'issue_summary': 'Missing module docstring', 'refactored_python_script': '\"\"\"This module contains decorators for handling user authentication.\"\"\"\\nfrom functools import wraps', 'severity': 'Moderate', 'score': 0.0}, {'start_line_number': 4, 'end_line_number': 4, 'original_python_script': 'def login_required(f):', 'issue_summary': 'Missing function or method docstring', 'refactored_python_script': '\"\"\"Decorator to check if a user is logged in before accessing a route.\"\"\"\\ndef login_required(f):', 'severity': 'Moderate', 'score': 0.0}, {'start_line_number': 8, 'end_line_number': 8, 'original_python_script': \"if 'user_id' not in session:\", 'issue_summary': \"Missing comment to explain the purpose of the 'user_id' check\", 'refactored_python_script': \"# Check if the user is logged in by looking for 'user_id' in the session\\nif 'user_id' not in session:\", 'severity': 'Minor', 'score': 8.0}, {'start_line_number': 9, 'end_line_number': 9, 'original_python_script': 'current_app.logger.warning(', 'issue_summary': 'Missing comment to explain the logging of unauthorized access attempts', 'refactored_python_script': '# Log unauthorized access attempts for security auditing\\ncurrent_app.logger.warning(', 'severity': 'Minor', 'score': 8.0}]}\n",
      "\n",
      "########################################################\n",
      "\n",
      "--- Ending Code Style And Consistency Reviewing on the file : uploaded_folder_gradio\\decorators.py ---\n",
      "###code style response### {'violations_count': 4, 'evaluation_score': 4.0, 'evaluation_issue_summary': 'The code has 4 issues, including missing module and function docstrings, and missing comments to explain the purpose of certain checks and logging. The issues are mostly minor or moderate, with scores ranging from 0.0 to 8.0.', 'evaluation_refactor_summary': \"The refactored code includes added docstrings for the module and the login_required function, as well as comments to explain the purpose of the 'user_id' check and the logging of unauthorized access attempts. These changes improve the code's readability and maintainability.\", 'evaluation_details': [{'start_line_number': 1, 'end_line_number': 1, 'original_python_script': 'from functools import wraps', 'issue_summary': 'Missing module docstring', 'refactored_python_script': '\"\"\"This module contains decorators for handling user authentication.\"\"\"\\nfrom functools import wraps', 'severity': 'Moderate', 'score': 0.0}, {'start_line_number': 4, 'end_line_number': 4, 'original_python_script': 'def login_required(f):', 'issue_summary': 'Missing function or method docstring', 'refactored_python_script': '\"\"\"Decorator to check if a user is logged in before accessing a route.\"\"\"\\ndef login_required(f):', 'severity': 'Moderate', 'score': 0.0}, {'start_line_number': 8, 'end_line_number': 8, 'original_python_script': \"if 'user_id' not in session:\", 'issue_summary': \"Missing comment to explain the purpose of the 'user_id' check\", 'refactored_python_script': \"# Check if the user is logged in by looking for 'user_id' in the session\\nif 'user_id' not in session:\", 'severity': 'Minor', 'score': 8.0}, {'start_line_number': 9, 'end_line_number': 9, 'original_python_script': 'current_app.logger.warning(', 'issue_summary': 'Missing comment to explain the logging of unauthorized access attempts', 'refactored_python_script': '# Log unauthorized access attempts for security auditing\\ncurrent_app.logger.warning(', 'severity': 'Minor', 'score': 8.0}]}\n",
      "--- Starting DRY Modularity Review on the file : uploaded_folder_gradio\\decorators.py ---\n",
      "failed to invoke the DRY & Modularity Agent Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01jj9emgbcex2amvxgb275xggv` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199817, Requested 1012. Please try again in 5m58.061999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "##dry response## []\n",
      "--- Starting Security Compliance Review on the file : uploaded_folder_gradio\\decorators.py ---\n",
      "failed to invoke security agent due to Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01jj9emgbcex2amvxgb275xggv` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199816, Requested 428. Please try again in 1m45.366s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "##security response## []\n"
     ]
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2588bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a498b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4cc2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
